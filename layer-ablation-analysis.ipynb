{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8791954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, default_data_collator\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "def read_table(path): \n",
    "    return pd.read_csv(path, sep=\"\\t\" if path.endswith(\".tsv\") else \",\")\n",
    "\n",
    "def load_split(path, text_col, label_col):\n",
    "    df = read_table(path)\n",
    "    return df[text_col].astype(str).tolist(), df[label_col].astype(int).tolist()\n",
    "\n",
    "class BinaryHateDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=500):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tok(self.texts[idx], truncation=True, max_length=self.max_len,\n",
    "                       padding='max_length', return_tensors='pt')\n",
    "        return {'input_ids': enc.input_ids.squeeze(), 'attention_mask': enc.attention_mask.squeeze(), 'labels': torch.tensor(self.labels[idx], dtype=torch.long)}\n",
    "\n",
    "def predict_labels(model, dataset, batch_size=128):\n",
    "    model.eval()\n",
    "    dl = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=default_data_collator)\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            _ = batch.pop(\"labels\")\n",
    "            batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "            logits = model(**batch).logits\n",
    "            preds.append(logits.argmax(dim=-1).cpu().numpy())\n",
    "    return np.concatenate(preds, axis=0)\n",
    "\n",
    "def compute_metrics_all(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1_bin = f1_score(y_true, y_pred, average=\"binary\")\n",
    "    f1_mac = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    return float(acc), float(f1_bin), float(f1_mac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14bedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "HF_USERNAME = \"iproskurina\"\n",
    "MODEL_NAME  = \"bert-base-cased\" #  facebook/opt-125m\n",
    "DATASETS    = [\"hatexplain\"] # [\"hatexplain\",\"ihc\",\"sbic\",\"olid\"]\n",
    "TEXT_COL    = \"sentence\"\n",
    "LABEL_COL   = \"label\"\n",
    "SEEDS       = [0,1,2,3,4]\n",
    "MAX_LEN     = 500\n",
    "BATCH_SIZE  = 128\n",
    "\n",
    "OUT_DIR = Path(\"outputs\"); OUT_DIR.mkdir(exist_ok=True)\n",
    "base_model_name = MODEL_NAME.split(\"/\")[-1]\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for seed in SEEDS:\n",
    "        set_seed(seed)\n",
    "        repo_id = f\"{HF_USERNAME}/{base_model_name}-{dataset}-s{seed}\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(repo_id, use_fast=True)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(repo_id).to(DEVICE)\n",
    "        if getattr(model.config, \"pad_token_id\", None) is None and tokenizer.pad_token_id is not None:\n",
    "            model.config.pad_token_id = tokenizer.pad_token_id\n",
    "        full_rows, full_cache = [], {}\n",
    "        for dataset_eval in DATASETS:\n",
    "            eval_path = f\"{dataset_eval}_test.csv\"\n",
    "            x, y = load_split(eval_path, TEXT_COL, LABEL_COL)\n",
    "            ds = BinaryHateDataset(x, y, tokenizer, max_len=MAX_LEN)\n",
    "            y_pred_full = predict_labels(model, ds)\n",
    "            acc_full, f1b_full, f1m_full = compute_metrics_all(np.array(y), y_pred_full)\n",
    "            full_rows.append({\n",
    "                \"removed_layer\": -1,\n",
    "                \"eval_set\": dataset_eval,\n",
    "                \"acc_full\": acc_full,\n",
    "                \"f1_binary_full\": f1b_full,\n",
    "                \"f1_macro_full\": f1m_full,\n",
    "                \"n\": int(len(y)),\n",
    "            })\n",
    "            full_cache[dataset_eval] = (np.array(y), y_pred_full.astype(float))\n",
    "        pd.DataFrame(full_rows).to_csv(\n",
    "            OUT_DIR / f\"{base_model_name}__{dataset}__seed{seed}__full.csv\", index=False\n",
    "        )\n",
    "        if hasattr(model, \"bert\"):\n",
    "            embed_type, layer_list = \"bert\", model.bert.encoder.layer\n",
    "        elif hasattr(model, \"model\") and hasattr(model.model, \"decoder\") and hasattr(model.model.decoder, \"layers\"):\n",
    "            embed_type, layer_list = \"opt\", model.model.decoder.layers\n",
    "        L = len(layer_list)\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        rows = []\n",
    "        for k in range(L):\n",
    "            pruned = AutoModelForSequenceClassification.from_pretrained(repo_id).to(DEVICE)\n",
    "            if getattr(pruned.config, \"pad_token_id\", None) is None and tokenizer.pad_token_id is not None:\n",
    "                pruned.config.pad_token_id = tokenizer.pad_token_id\n",
    "            if embed_type == \"bert\":\n",
    "                enc = pruned.bert.encoder\n",
    "                keep = [i for i in range(L) if i != k]\n",
    "                enc.layer = nn.ModuleList([enc.layer[i] for i in keep])\n",
    "                pruned.config.num_hidden_layers = len(enc.layer)\n",
    "            else:\n",
    "                dec = pruned.model.decoder\n",
    "                keep = [i for i in range(L) if i != k]\n",
    "                dec.layers = nn.ModuleList([dec.layers[i] for i in keep])\n",
    "                if hasattr(pruned.config, \"num_hidden_layers\"):\n",
    "                    pruned.config.num_hidden_layers = len(dec.layers)\n",
    "            pruned.eval()\n",
    "            for dataset_eval in DATASETS:\n",
    "                eval_path = f\"{dataset_eval}_test.csv\"\n",
    "                x, y = load_split(eval_path, TEXT_COL, LABEL_COL)\n",
    "                y = np.array(y)\n",
    "                ds = BinaryHateDataset(x, y, tokenizer, max_len=MAX_LEN)\n",
    "                y_pred_pruned = predict_labels(pruned, ds).astype(float)\n",
    "                y_pred_full = full_cache[dataset_eval][1]\n",
    "                # ttest\n",
    "                t_stat_pred, p_val_pred = ttest_rel(y_pred_full, y_pred_pruned, nan_policy=\"omit\")\n",
    "                acc_p, f1b_p, f1m_p = compute_metrics_all(y, y_pred_pruned)\n",
    "                rows.append({\n",
    "                    \"removed_layer\": k,\n",
    "                    \"eval_set\": dataset_eval,\n",
    "                    \"t_rel_pred\": float(t_stat_pred),\n",
    "                    \"p_rel_pred\": float(p_val_pred),\n",
    "                    \"acc_pruned\": acc_p,\n",
    "                    \"f1_binary_pruned\": f1b_p,\n",
    "                    \"f1_macro_pruned\": f1m_p,\n",
    "                    \"n\": int(len(y)),\n",
    "                })\n",
    "            del pruned\n",
    "            torch.cuda.empty_cache()\n",
    "        pd.DataFrame(rows).to_csv(\n",
    "            OUT_DIR / f\"{base_model_name}__{dataset}__seed{seed}__ablation_ttest_preds.csv\", index=False\n",
    "        )\n",
    "        print(f\"Model {repo_id} processed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
